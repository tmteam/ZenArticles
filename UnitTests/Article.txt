
Гипотетический продукт оунер Инокентий готовил к выпуску механические наручные часы в стартапе «ТакиТик».

Высококлассный тестировщик Михаил, в процессе подготовки к выпуску, провел комплексную процедуру тестирования, включающую в себя:

- сверку времени с церном два раза в день на протяжение недели (был заключен контракт с церном)
- проверку точности времени после перелета в йцуйцу  на горе «цгйцуйц» в камбоджии, где гравитационная постоянная равнялась 9.81. 
- проверку точности времени по возвращению в оффис, после двух 12 часовых перелетов
- проверку громкости хода секундной стрелки(в том числе для часов в перевернутом положение)

и многое другое.

Все тесты были пройдены, подписаны и, даже автоматизированы(что бы проходить  для каждого нового экземпляра часов). Долгожданный день релиза настал, но  спустя пару месяцев Продукт оунер Инокентий, отдыхая в Австралии заметил некоторые изъяны в работе часов:

- Часовая стрелка  спешила
- Секундная стрелка пропускала секунды (иногда).
- Минутная стрелка показывала на север.

Пересечение экватора ли, обилие крокодилов ли - что то определенно изменило ход времени..

- Как вы могли?! - кричал по скайпу Инокентий
- Мы точно все протестировали - тихо мямлил Михаил
- Нам конец, кричал основатель стартапа.
- Вы уволены - орал HR на разработчиков
- У нас есть две недели на исправление - спокойно подытожил скрам мастер.

Привлеченный для исправления ошибок предыдущей команды, высококлассный программист Джо, открыв часы обнаружил некоторые изъяны архитектуры.

Тщательно отсортировав шестеренки по степени овальности, изоленту по цветовой гамме и стукнув дважды по маленькой черной коробочке с надписью «ХЗ» -  он принял взвешенное решение опытного разработчика - бежать.

Еще через месяц, стартап «Тактики» был закрыт, а его оборудование доедали оголодавшие инвесторы.

Стоп. Хватит этого софтвейр -достоевского! 

Что сделал «Тики так» не так? 

Были ли их разработчики низкоквалифицированны? Нет. Это были профи
Был ли их серам мастер слишком мастеровым? Вероятно, но мы не считаем это минусом.
Было ли покрытие тестами? Да. Отличное покрытие биологическим, и автоматическим тестами. 

Так что не так?

Если мы с вами управляем АЭС, то нам не достаточно полных «функциональных» показателей работы станции типа «выработка тока», «общий радиационный фон рядом» итд. Мы хотим быть уверенными в том, что станция построена по всем возможным канонам, и в данный момент, ни в каком из реакторов не началось длительных и необратимых последствий. В противном случае мы будем напрочь лишены сна (или совести), у нас будет дергаться веко. Мы будем далеки от дзена, а значит скоро разлюбим то что мы делаем, ведь стараясь и вкладывая усилия хочется видеть текущий и легко формализуемый  результат. Мы хотим видеть полную картину здесь и сейчас. И для этого существуют Юнит тесты. Но давайте обо всем по порядку.

Атомарное тестирование

Минимализм

Вернемся к ошибкам ТакиТика.  Рассмотрим простейшую сборку из двух шестеренок в которой шестеренка А имеет 100 зубчиков и делает один оборот за 1 день. А шестеренка Б обладает 199 зубчиками. Каждая из шестеренок имеет один дефектный зуб (помечен красным) Сам по себе этот зуб не проявляет себя, пока не встретится с другим подобным зубом. И тогда механизм либо заклинит, что очевидно, либо будет пропущен шаг - и тогда заметить проблему будет очень сложно.

Как мы можем выявить этот дефект? Зубчики гарантированно столкнутся раз в 199 оборотов первой шестеренки. Тоесть мы заметим эффект в течение 0 -  199 дней. Вполне вероятно что именно это было причиной проблем Такитика (а не крокодилы и экватор). Биологический или функциональный автотест покажет такую проблему очень не скоро. Является ли панацеей ускорение теста (быстрее крутить шестерни)? Если сборка позволяет то да. Но если сборка содержит не две а десять шестерней то и ускоренный тест ничем нам не поможет.

Проблема заключается в том, что если мы имеем N объектов, каждое из которых может  находится в одном из Xi состояний, то теоретическое количество состояний системы Y будет равняться произведению количества состояний элементов:  Y = X1*X2*X3….*Xn. Нам же нужно проверить все возможные состояния для спокойного сна. И если в случае с шестеренками - все возможные состояния можно проверить одним тестом (пускай и очень долгим). То в случае холодильника - придется создавать огромный зоопарк  сложных и долгих тестов (со свининой, электричеством и грязными руками).

Вывод прост - Чем меньше различных объектов участвуют в тестирование - тем меньше работы, больше дзена и крепче сон Инокентия.

Если протестировать хотя бы одну шестеренку (например А) и найти в ней проблемный зубчик, то интеграционный тест сборки уже будет проверять только шестерню Б (с ее 199 состояниями) и взаимодействие между шестернями. А если проверить еще и Б, то интеграционный тест можно провести быстро, и для галочки. Дзен!

А это значит, что нам нужен тест - который тестирует минимально возможный объект (или группу объектов) с минимальной зависимостью от окружения.

И еще раз минимализм

Тестировать шестеренку можно разными способами, от эффективных до абсолютно безумных.Часто можно встретить тестирование сценариями. Для шестерни, такой сценарий будет выглядеть примерно так:

- Создать шестеренку
- Раскрутить ее до 1000 об в секунду
- Проверить что шестеренка не взорвалась
- Раскрутить до 10 об в секунду. 
- Проверить что при кручение - шестерня не люфтит
- Раскрутить шестерню в другую сторону
- Проверить что шестерня не взорвалась
- После всех издевательств над шестерней, для каждого зубчика проверить его геометрию

Такой сценарий покажет нам «Годится ли шестерня для часов или нет». Это неплохо. В добавок эти тесты покажут те нюансы, о которых вы даже не задумывались на этапе проектировки. Например раскрутка до безумной скорости - покажет качество металла - а это ресурс. 

Этот тест безусловно хорош, но если присмотреться…

1) Мы не видим что конкретно сломалось.
 
Сценарный тест покажет проходит ли объект сценарий или нет, и в лучшем случае - на каком этапе тест завершился неудачей. Если в объекте есть несколько дефектов - мы не увидим корневого. Мы увидим только факт того что «когда крутили назад, после всего пережитого - оно наконец то разлетелось»

2) Проверка зубчиков на геометрию, как и самой геометрии шестеренки происходит после раскрутки шестерни до 1000 об в секунду. А не выправила ли эта раскрутка сам объект?
3) Сам тест будет непонятным, и требует комментариев, что приводит к большему количеству трудозатрат и, самое главное - необходимости поддерживать комментарии в консистентном состоянии
4) Любое изменение специфики потребует изменения большинства сценарных тестов, связанных с объектом. 

Как итог - вы не захотите вносить даже малейшее изменение в объект, так как никто не хочет исправлять множество однообразных, непонятных тестов, не понимая что именно и где сломалось.
Этот тест свяжет вам руки, и, в итоге вы выпилите его, либо разочаруетесь в тестирование вообще.
Ситуация идентична тестированию сборки - желание сделать все и в одном месте вновь приводит к хаосу. 
Чем больше тест - тем больше с ним проблем, поэтому разобьем тесты на минимально возможные элементы:

- Создать шестеренку -> Раскрутить до 1000 об в сек по часовой стрелке -> проверить что не взорвалась
- Создать шестеренку -> Раскрутить до 1000 об в сек против часовой стрелке -> проверить что не взорвалась
- Создать шестеренку -> Раскрутить до 10 об в сек -> проверить что шестерня не люфтит
Для каждого зубчика
- Создать шестеренку-> Замерить зубчик-> сравнить замер с эталоном

Теперь мы имеем набор тестов для объекта, каждый из которых тестирует отдельный его аспект. Сравним со сценариями:
1) Мы видим что конкретно сломалось
2) Зубчики проверяются в изначальном состояние
3) Каждый тест предельно ясен
4) Изменения в специфике модуля приводят к изменению в малом количестве тестов

Все эти минималистичные тесты используют один и тот же паттерн: Создай среду -> Проведи действия -> Проверь результат. И этот паттерн называется AAA (Arrange -> Act -> Assert)

В дополнение к бонусам мы получаем прекрасную документацию на  шестерню. Если добавить к ней дополнительных тестов то ее можно использовать как тз. 

Вывод: Хорошие тесты - минималистичны и являются ААА тестами

Любой тест, который вываливается за рамки AAA можно разбить на несколько AAA тестов, а так как усложненные тесты больше подверженны ломучести, хуже читаются и не показывают что именно работает/ не работает - данное требование одно из самых полезных.

В целом приемлем любой тест который устойчив к изменениям, читабелен, и понятно что он исследует без изучения кода. Однако, из моего опыта это почти всегда вариации на тему AAA.


Пространственно - временной минимализм.

Сколько должен длиться один тест?  Допустим у вас есть 10 000 тестов. Если один тест занимает 1 секунду - то весь прогон тестов займет около трех часов.
А значит вы будете его делать крайне редко. Этот прогон будет ассоциироваться у вас с негативом, ужасной бюрократией ну или игрой в пинг понг (нет). Этот набор тестов не сделает вас счастливым.

Однако если 1000 тестов будет проходить за 10 секунд - это позволит вам  вносить сколько угодно изменений в код, эксперементировать.  видя результат изменений практически мгновенно. Сколь угодно сложное станет контролируемым, а значит сделает вас спокойным и счастливым. Мой личный критерий - тест должен длиться не более 30 мс. Желательно не более 10.  Все что более - нужно менять/ дробить и декостылировать. 

Вывод: Хорошие тесты - быстрые. Очень быстрые!


Однозначность. 

И вот перед нами уже есть красивый диспетчерский пункт мониторинга, который показывает состояние модулей, практически в реальном времени. Тысячи лампочек горят зеленым и одна красной. Цель максимум - не заглядывая в код красной лампочки понять что произошло не так. 

Это возможно если мы тестируем нечто конкретное и понятное (Например форму зубчика), соблюденаем минималистичность теста и используем информативные наименования, по правилу, одинаковому для всех тестов. Например

Frege_OpenTheDoor_LightTurnsOn (по правилу Unit_Action_ExpectedResult)

Хорошие тесты - обладают информативными и однородными наименованиями

и последнее. Хорошие тесты - не должны моргать. Если тест работает один раз из 99 то это это значит что «не прошедший тест не обязательно значит что ПО сломано» а прошедший тест не значит что По Работает. Недоверие показателям тестов, мольбы богини дисперсии что бы тесты прошли доведут вас до нервного тика очень быстро. «Не верь тому что видишь» и «не надейся что это работает» - не лучшие друзья спокойного человека. Так что Хорошие тесты не зависят от случайных величин и или гонок потоков. Эти  всегда дают один и тот же результат по своей натуре

Не копай огород шестерней

Если вы выполнили все пункты перечисленные сверху, но при этом в вашем тесте проверяется способность шестерни копать картошку, а холодильника хранить трупы - вы сбились с пути.
Сценарий не специфичный для исследуемуемого объекта может сегодня и работает, но завтра он поломается при малейшем изменении исходного кода. Шестерня должна крутиться и быть ровной, холодильник должен холодить. Нам нужны тесты, которые исследуют Api элемента. Все остальные тесты рано или поздно будут поломаны либо глубоко не поняты, а ведь им нужно понимание и забота.


Тесты удовлетворяющие всем этим условиям называются Юнит тестами. В данном тексте я буду называть их «атомарными» так как Юнитом можно назвать и автомобиль и человека и микросервис. Также, 
Атомарность лучше описывает стремление.к минимализму в размере теста, время его прохождения и тестированию.


Путь к дзену дизайна.

Допустим у нас есть модель пользователя, с одной - очень важной характеристикой - длинной носа:

User
	- NoseLength 


и фабрика по производству носатых пользователей 

UserFactory
	+ User Create(noseLength)

Скорее всего внутри метода Create будет простейшая строчка.

User Create(noseLength)
	return new User{noseLength = noseLength}

Однако начиная писать тесты - забудьте про код исследуемого объекта. Наши тесты исследуют Api элемента. А это значит что  нужно написать спецификацию метода в виде теста:

UserFactoryTest()
	user = UserFactory.Create(5)
	Check.That(user. NoseLength).Equals(5)

 Но мы договорились использовать однозначные наименования. Что именно тестирует этот код?  И позвольте - что за магические константы? Значит ли это что фабрика работает только при длиннее носа 5? И почему именно 5? Этот тест хрупок и непонятен. Подкорректируем его

UserFactoryCreate_NoseLengthIsPositive_CreatesUserWithCorrectLength()
        testLength = 5;
	user = UserFactory.Create(expectedLength)
	Check.That(user. NoseLength).Equals(testLength)

Уже лучше. Но все же. Хочется проверить и при других положительных числах. К счастью большинство тестовых фреймворков позволяют легок это сделать примерно так:

[expectedLength = {1, 5, 10, 100}]
UserFactoryCreate_NoseLengthIsPositive_CreatesUserWithCorrectLength(expectedLength)
	user = UserFactory.Create(expectedLength)
	Check.That(user. NoseLength).Equals(testLength)

С обычными носами разобрались. Можно ли сказать что тестирование нашей фабрики закончилось? Описали ли мы весь API класса? Определенно нет. Как насчет отрицательной/нулевой/бесконечной длинны носа? 
Тут я, как разработчик фабрики чешу голову. «Ой. Кажется фабрика должна кидать исключение в этом случае». Застолбим это правило:


[ExpectedLength = {-10, -1, 0, inf, 1/0, -1/0 }]
UserFactoryCreate_NoseLengthIsNotPositive_ThrowsInvalidNoseException(badLength)
        Check.That(
			UserFactory.Create(expectedLength))
		.Throws(InvalidNoseException);

И теперь можно поправить код фабрики:
User Create(noseLength)
	if (noseLength >0 )	return new User{noseLength = noseLength}
	else throw InvalidNoseException

И еще раз прогнать тесты, убедившись что все хорошо. Вы железобетонно продвинулись на шаг в решении вашей задачи.

Безусловно мы потратили уйму времени на простейший метод простейшей фабрики, но посмотрите еще раз на эти тесты. Они заставили найти ошибку в нашем классе и не только сделали код надежным сейчас - но и избавили нас от внезапных и глупых ошибок в будущем. 

Выводы:
- Тесты требуют много времени. Как правило они удлиняют разработку в 2 - 3 раза
- Тесты требуют аккуратного программирования. Код тестов должен быть не хуже чем основной код. Он должен быть читабельным и гибким.
- Помимо повышения надежности кода сейчас, они избавляют от  ошибок в будущем.
- Правильный тест является исчерпывающей автодокументацией класса. Не знаете что делает класс? Посмотрите его тест.
- Концентрация на API класса позволяет улучшить дизайн класса
- Желательно писать тесты перед написанием кода. Мыслить на уровне API - это приводит к более чистому API так как для непонятного API писать тесты сложно и лень. Легче поправить класс.

 Большая часть пользы атомарного тестирования проявляется не здесь и сейчас. Чистая архитектура, и доверие протестированным элементам позволяет избежать ошибок в будущем и мотивирует продумывать API и повторно использовать уже созданные элементы, так как это просто проще чем переписывать тесты. 

Тернистый путь к дзену.

Среди наших пользователей частенько встречаются буратины. Согласно принципам дизайна мы обязательно должны отразить это в коде:

Pinocchio: User
       +sayLie()

И сразу отразить это в тесте

Pinoссрio_Lies_NoseBecomesBiggerThanBefore()
	originNoseLength = 1
         pinocchio = new pinocchio{noseLength = originNoseLength}
	pinocchio.sayLie()
	Check.That(pinocchio.noseLength).IsGreaterThan(originNoseLength)

Тест проверяет что  произнесение пользователем лжи увеличивает длину носа. Это абсолютно корректный тест и наверное он переживет меня. Но насколько именно должен увеличиться нос?
Лезем в текст метода:

sayLie()
		noseLength+= 7 //Универсальная константа лжи

Пожалуй это яркий пример того, почему мы не любим магические числа и комментарии. Идем к боссу, допрашиваем его. Оказывается сейчас у пинокио нос растет просто на 7 пунктов ибо «8 много а 6 мало». Но в будущем. по вторникам, вероятно это будет не так.  Похоже это поведение нужно отделить от пинокио. 

LieNoseEnlarger
 	+number GetNewNoseLength(originNoseLength)

Pinocchio: User
        - enlarger
	Pinocchio()
		enlarger = new LieNoseEnlarger()
	sayLie()
		noseLength = enlarger. GetNewNoseLength(noseLength)

Но трестируя подобный класс мы будем тестировать пинокио одновременно со поведением увеличения носа. Это конфликтует с принципом минимализма и это приведет к тому, что при измении этого поведение в будущем упадет тест Пинокио (хотя Пинокио останется корректным), а мы желаем длительной жизни нашим тестам. Также, в случае возникновения проблемы мы не будем знать где именно она возникла - в увеличителе носа, или  пинокио. 

Что бы решить эту проблему нужно позволить подставлять специфичное поведение (увеличения носа) в конструктор. Однако, следите за пальцами, если мы подставим оригинальное поведение, используемое пинокио по стандарту,
То мы по прежнему не можем быть уверенны где именно будет проблема. А значит нам нужно использовать объект в котором мы уверены. Вариант первый - это написать отдельный тест для LieNoseEnlarger, а затем использовать LieNoseEnlarger в тесте для пинокио, Второй вариант - сделать заглушку, фейковый объект. Оба варианта приемлемы но так как эта статья про атомарное тестирование, то мы выберем вариант с подставным поведением. 

StubNoseEnlarger: ILieNoseEnlarger
	- EnlargeFactor = 1
	number GetNewNoseLength(originNoseLength)
		return originNoseLength+EnlargeFactor

Эта заглушка увеличивает длину носа на строго заданную величину
Изменим Буратино, чтобы можно было использовать ее.

Pinocchio: User
        - enlarger
	Pinocchio(customEnlarger)//можно добавить свой увеличитель носа
		enlarger = customEnlarger
	Pinocchio() // или использовать стандартный
		enlarger = new LieNoseEnlarger()
	sayLie()
		noseLength = enlarger. GetNewNoseLength(noseLength)

Я надеюсь вы узнали паттерн «стратегия»?  Теперь мы можем добавить еще один, уточняющий тест для Буратино:

Pinoссрio_Lies_NoseLengthIncreasesByOne
	originNoseLength = 1
	noseIncreasing = 1
	enlargerStub = new StubNoseEnlarger{enlargeFactor = noseIncreasing}
        pinocchio = new pinocchio{enlarger =enlargerStub, noseLength = originNoseLength}
	pinocchio.sayLie()
	Check.That(pinocchio.noseLength).Equals(originNoseLength+noseIncreasing)
  
Таким образом написание теста вынудило меня сделать код более гибким, исполнить  SR, OC и DI-принципы, а значит заложиться на будущее.

Выводы:
	- заглушки это круто!
	- тесты позволяют проверить гибкость и продуманность трестируемого элемента
	- тесты склоняют нас к использованию принципа единой ответственности/принципу единой изменчивости
	- тесты склоняют нас к использованию принципа «открытого-закрытого», так как теперь мы можем менять поведение носа буратино без изменения самого буратино
	- тесты, неразрывно связаны с рефакторингом и корректировкой Api класса. 

Несовершенный мир

Продукт оунер Инокентий недавно обнаружил что у пользователей есть время рождения и он сразу захотел использовать точный возраст в вычислениях отдела Data-Science
Для нас это значит добавление поля BirthDate и метода getAge() в базовый класс User

User
	- birthDate : DateTime
	+TimeStamp getAge()
		return DateTime.getCurrent() - birthDate 

А также добавление теста

NewUser_getAge_AgeEquals	
	user = new User{birthDate = DateTime(1988, 12, 01)}
         age = user.getAge();
	Check.That(age).EqualsTo(DateTime,getCurrent() - user.birthDate)

Вероятно я был пьян, когда писал это. Тест иногда даже проходил, поэтому можно сделать вывод что фича была наверное сделана. Шучу.
Возраст пользователя поменялся между строчками  age = user.getAge() местом его проверки. Очевидно что дело в зависимости класса пользователя от DateTime.now. Однако такую зависимость нельзя назвать
Плохой или вредной. Напротив - в данном месте она очень даже естественна. Однако тест для класса в таком виде мы все же не можем написать. Придется его уродовать, внедрением зависимости на текущее время.

User
	- currentTimeLocator() = DateTime.getCurrent //локатор текущего времени ссылается на метод получения времени
	- birthDate : DateTime
	+TimeStamp getAge()
		return currentTime() - birthDate 

Теперь можно переписать тест

NewUser_getAge_AgeEqualsDeltaBetweenNowAndBirth	
	nowTime = DateTime(2018,01,01)
	user = new User{
		birthDate = DateTime(1988, 12, 01)
         	currentTimeLocator = function { return nowTime; }
	}
         age = user.getAge();
	Check.That(age).EqualsTo(nowTime - user.birthDate)

Можно сказать что мы сделали внедрение и инверсию зависимости и класс стал лучше с точки зрения дизайна (нет). Зависимость от текущего времени вреатли пригодится нам в коде, а вот читабельность класса слегка упала.  Точка расширения (currentTimeLocator) сделанная исключительно в целях тестирования называется «Зазор». 

Вывод: Рефакторинг при тестировании бывает не только позитивным. Иногда приходится «портить» дизайн класса во благо тестирования. Это походит на диагностический разъем на тыльной стороне бытовой техники.
	

Мой нелюбимый пример

Добавим в фабрику пользователей метод, создающий гостя со случайной длинной носа.

User CreateRandom(maxNoseLength)
	return Сreate(Random.Get(0, maxNoseLength))

Как протестировать его? В своей практике я не раз встречал код на подобие этого:

CreateRandom_RepeatMultipleTimes_CreatesUserWithCorrectLength()
	maxLength= 100;
	repeat 10000000 times:
		user = UserFactory.CreateRandom(maxLength)
		Check.That(user.noseLength).LessThan(maxLength)

Кажется это тест неплох. Мы запускаем этот тест и видим что он проходит. Однако в полночь, прям перед релизом - ваш босс замечает что он не прошел. Вы повторяете процедуру - и о чудо - он опять прошел.
Релиз отложен, вы в недоумении. Босс в мыле. Поздравляем! В вашей компании завелся плавающий тест. Исконной же причиной является то, что Random может выдать в том числе 0, что, из текста выше должно приводить к InvalidNoseException

Плавающий тест - лучший способ поистрепать нервы и не доверять результам тестирования, себе, железу и вашему босу. Честно говоря - лучше вообще его удалить, так как его позитивный результат не скажет ни о чем, а негативный лишь создаст слишком много вопросов. Я всегда бросаюсь с яростью на исправление таких тестов в первую очередь, так как это лживые друзья.

Какие принципы атомарного тестирования мы нарушили? 	Сразу несколько:
1) Хорошие тесты не зависят от случайных величин, даты запуска и или гонок потоков. Они  всегда дают один и тот же результат по своей натуре
2) Минимальность теста по времени. Мы прогнали тест 10 миллионов раз. Даже если эта операция занимает микросекунду - тест займет 10 секунд. В хороший день я успею уснуть за это время
3) Минимальность теста. Можно сказать что мы прогнали сценарий использования фабрики. Это хорошо что мы сами написали код и знаем что там нет паразитных состояний. Но это обманчивая привычка. Код может поменяться. Ужасный Джуниор Вася может оставить там свой автограф - а вы и не заметите. И в конце концов - вы не тестируете API. Вы умоляете класс чтобы он запустился. Это напоминает тест отчаяния.
4) Минимальность исследования объекта в изоляции от окружения. Наш тест зависит от внешней функции Random. Не глядя на код фабрики - непонятно что служит причиной моргания теста - специфика работы фабрики или рандома?

Исправить проблему -просто. Достаточно изменить код фабрики

User CreateRandom(maxNoseLength)
	while(true)
		result =  Сreate(Random.Get(0, maxNoseLength));
		if(result>0)
			return result;

Для тестирования этой функциональности нужно будет постараться

IRandomGenerator
	- number Get()

RandomGenerator: IRandomGenerator
	Get()
		return Random.Get()

RandomGeneratorStub	
	-number[] stubNumbersSequence 
	position = -1;
	Get()
		position++;
		return stubNumbersSequence[position]

CreateRandom_RandomNumberIsPositive_ReturnsUserWithSpecifiedNoseLength()
         randomNumber = 3;
	 stub = RandomGeneratorStub { stubNubersSequence = {randomNumber}}
   	 var user = UserFactory.CreateRandom(randomNumber+1, stub);
	 Check.That(user.noseLength).Equals(randomNumber);
	
CreateRandom_RandomNumberIsZero_ReturnsUserWithNoseLengthOfSecondRandomNumber()
         randomNumber = 3;
	 stub = RandomGeneratorStub { stubNubersSequence = {0, randomNumber}}
   	 var user = UserFactory.CreateRandom(randomNumber+1, stub);
	 Check.That(user.noseLength).Equals(randomNumber);

Тест получается достаточно сложным и изменяет чистый интерфейс CreateRandom. Более того - он не тестирует API - он тестирует внутреннюю работу метода. 
Это черевато тем, что при первом же изменении внутренней логики метода CreateRandom - все связанные тесты придется переписать либо удалить. Это спорная ситуация, и я в ней предпочел бы потратить
cвое время на покрытие других частей системы. 

Выводы: не надо покрывать тестами все подряд.

Базисные правила

В течении статьи я вывел множество рекомендаций для атомарного Unit -тестирования

- ААА - структура
- Один трестируемый элемент
- Минимализм теста 
- Скорость 
- устойчивость к изменениям кода
- однозначность выполнения
- читабельное наименование
- Тестирование API

Итд. Но, кажется не написал и доли прочих нюансах о которых можно рассказать. Tdd/Tld/Bdd, State vs Behaviour и прочие бесчисленные подходы сознательно были пропущенны в этом посте. 
Зоопарк терминов правил и рекомендаций явно намекает на наличие более фундаментальных, базисных принципов.

- Принцип приборной панели. Картина атомарных тестов должна напоминать удобную приборную панель мониторинга кода. Отсюда следуют требования наименования,  минималистичности исследуемого объекта и зависимости от окружения, однозначности и  скорости  выполнения. Рефакторинг исходного кода.
- Эволюционный принцип (удачными считаются те тесты которые живут дольше всего). Приводит нас к минимзации тестов, тестированию API, AAA-тестированию, скорости выполнения, избирательности тестирования, качеству и читабельности кода тестов. Устойчивости относительно меняющегося кода. Рефакторинг исходного кода.
- Документный принцип (Тест описывает Api элемента). Автодокументация, надежность кода, качество кода, ААА, Наименования. Рефакторинг исходного кода.

Таким образом - каждый раз когда вы пишите тест ответьте на три вопроса:
1) Будет ли этот тест понятным индикатором на приборной панели?
2) Выживет ли этот тест через год при учете постоянно меняющихся требований и рефакторингов?
3) Можно ли использовать этот тест как документацию к исследуемому коду?

Такой же подход можно использовать при выборе целей тестирования.

Make the coding great again

В сознание обычного человека, тесты существуют для того, что бы протестировать существующую функциональность. Однако выше, текущая надежность кода была упомянута лишь как следствие или побочный эффект базисных принципов. Вероятно это вас удивит, но тестирование функциональности это лишь 40% смысла атомарных тестов. Основная же цель их написания - это архитектура. 
Атомарные тесты являются мощным драйвером написания SOLID кода и четким критерием рефакторинга (на этом подходе основана методология TestDrivenDevelopment). Расплывчатые термины «этот код плохо пахнет» или «декостылируем понемногу» заменяются на четкие «это нельзя протестировать атомарно» или «атомарный тест такого класса будет громоздким, хрупким и не очевидный). Из простоты тестирования можно легко обосновать такие термины как.ValueObject, pure function, а SOLID обретает смысл и становится приниципом а не рекомендацией.


Атомарные тесты - это замковый камень всех расплывачатых и зачастую противоречивых методик и принципов разработки ПО на микро уровне, таких как Solid, функциональное программирование, рефакторинг, ddd и многих других. Все эти методы естественным образом происходят из трех базисных правил приведенных выше. Все вновь обретает смысл и у вас на руках появляется четкий критерий (четкий после написания тысячи тестов, безусловно) использования того или иного подхода. Программирование прекращает быть попыткой укрощения хаоса и снова становится искусством.

С более практической стороны, требование по минимальному процентному покрытию кода атомарными тестами - четко формализуемо. В процессе его выполнения - даже самому ленивому программисту легче написать несколько хороших Solid элементов, или повыдергивать их из уже имеющегося God-класса, чем пытаться покрыть тестами класс на 2000 строчек кода. А ревьювить тесты, в свою очередь намного проще чем сам код. Так появляется единая метрика «процент покрытия атомарными тестами» которая является достаточно точным показателем качества микроархитектуры вашего приложения. Вы с большой долей вероятности получаете маленькие аккуратненькие элементы (классы, функции. Алгоритмы и структуры данных) для вашей конкретной задачи. Эти маленькие элементы являются фундаментом для сложной архитектуры. Их наличие намного упрощает создание больших и гибких приложений.

Также, показатель покрытия атомарными тестами можно использовать как метрику качества проведенного рефакторинга. Если программист за один день покрыл 2% модуля атомарными тестами которые прошли ревью - то это круто. Если же он покрыл 4% кода тестами то это в два раза круче.

Смысл написания атомарных юнит тестов, как правило - это на 40% тестирование функциональности, и на 60% инвестиции в будущее. Не всегда имеет смысл  покрывать такими тестами ваш блог, проверку гипотезы или  старый легаси код - это может оказаться не выгодно. Однако при разработке и поддержке большого приложения, которое планирует жить и развивать несколько лет - атомарные тесты становятся крайне выгодным оружием, которое к тому же держит разработчиков в тонусе. 

Но что самое важное - атомарные юнит тесты являются необходимым теоретическим, практическим и структурным фундаментом для самой действенной и мощной методики по созданию надежного кода и проверке его функционала здесь и сейчас. 
Методики, которая открывает возможность проведения «рефлекторного рефакторинга», и отнимает работу у отдела биологического тестирования. Назовем ее «Молекулярное тестирование», стоящей на стыке юнит и интеграционного тестирования. Но об этом я расскажу в следующий раз. 



 



 